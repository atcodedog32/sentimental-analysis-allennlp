{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "allennlpsenti_analysis.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "nCIg-iU6hWPe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "APdN3U0Cha9t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1928
        },
        "outputId": "20e99b1a-3b6f-46fc-e5e5-773b61588012"
      },
      "cell_type": "code",
      "source": [
        "!pip install allennlp"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: allennlp in /usr/local/lib/python3.6/dist-packages (0.8.0)\n",
            "Requirement already satisfied: matplotlib==2.2.3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.18.4)\n",
            "Requirement already satisfied: flask==1.0.2 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.15.4)\n",
            "Requirement already satisfied: parsimonious==0.8.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.8.0)\n",
            "Requirement already satisfied: pytz==2017.3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2017.3)\n",
            "Requirement already satisfied: jsonnet==0.10.0; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.10.0)\n",
            "Requirement already satisfied: moto==1.3.4 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.3.4)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.5.2)\n",
            "Requirement already satisfied: numpydoc==0.8.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.8.0)\n",
            "Requirement already satisfied: conllu==0.11 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.11)\n",
            "Requirement already satisfied: msgpack<0.6.0,>=0.5.6 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.5.6)\n",
            "Requirement already satisfied: awscli>=1.11.91 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.16.81)\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from allennlp) (4.28.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.1.0)\n",
            "Requirement already satisfied: overrides in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.9)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.4.1)\n",
            "Requirement already satisfied: gevent==1.3.6 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.3.6)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.2.5)\n",
            "Requirement already satisfied: flaky in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.4.0)\n",
            "Requirement already satisfied: cffi==1.11.5 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.11.5)\n",
            "Requirement already satisfied: tensorboardX==1.2 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.9.67)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.10.1)\n",
            "Requirement already satisfied: responses>=0.7 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.10.5)\n",
            "Requirement already satisfied: spacy<2.1,>=2.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.0.18)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.8.0)\n",
            "Requirement already satisfied: sqlparse==0.2.4 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.2.4)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.0.23)\n",
            "Requirement already satisfied: flask-cors==3.0.7 in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.0.7)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.6/dist-packages (from allennlp) (5.5.0)\n",
            "Requirement already satisfied: pytorch-pretrained-bert==0.3.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.20.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.2.3->allennlp) (2.5.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.2.3->allennlp) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.2.3->allennlp) (2.3.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.2.3->allennlp) (1.0.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.2.3->allennlp) (1.11.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2018.11.29)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (1.22)\n",
            "Requirement already satisfied: Werkzeug>=0.14 in /usr/local/lib/python3.6/dist-packages (from flask==1.0.2->allennlp) (0.14.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask==1.0.2->allennlp) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.6/dist-packages (from flask==1.0.2->allennlp) (2.10)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask==1.0.2->allennlp) (7.0)\n",
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.6/dist-packages (from moto==1.3.4->allennlp) (0.11.0)\n",
            "Requirement already satisfied: cryptography>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from moto==1.3.4->allennlp) (2.4.2)\n",
            "Requirement already satisfied: pyaml in /usr/local/lib/python3.6/dist-packages (from moto==1.3.4->allennlp) (18.11.0)\n",
            "Requirement already satisfied: python-jose<3.0.0 in /usr/local/lib/python3.6/dist-packages (from moto==1.3.4->allennlp) (2.0.2)\n",
            "Requirement already satisfied: botocore>=1.9.16 in /usr/local/lib/python3.6/dist-packages (from moto==1.3.4->allennlp) (1.12.67)\n",
            "Requirement already satisfied: jsondiff==1.1.1 in /usr/local/lib/python3.6/dist-packages (from moto==1.3.4->allennlp) (1.1.1)\n",
            "Requirement already satisfied: mock in /usr/local/lib/python3.6/dist-packages (from moto==1.3.4->allennlp) (2.0.0)\n",
            "Requirement already satisfied: boto>=2.36.0 in /usr/local/lib/python3.6/dist-packages (from moto==1.3.4->allennlp) (2.49.0)\n",
            "Requirement already satisfied: cookies in /usr/local/lib/python3.6/dist-packages (from moto==1.3.4->allennlp) (2.2.1)\n",
            "Requirement already satisfied: aws-xray-sdk<0.96,>=0.93 in /usr/local/lib/python3.6/dist-packages (from moto==1.3.4->allennlp) (0.95)\n",
            "Requirement already satisfied: docker>=2.5.1 in /usr/local/lib/python3.6/dist-packages (from moto==1.3.4->allennlp) (3.6.0)\n",
            "Requirement already satisfied: sphinx>=1.2.3 in /usr/local/lib/python3.6/dist-packages (from numpydoc==0.8.0->allennlp) (1.8.2)\n",
            "Requirement already satisfied: colorama<=0.3.9,>=0.2.5 in /usr/local/lib/python3.6/dist-packages (from awscli>=1.11.91->allennlp) (0.3.9)\n",
            "Requirement already satisfied: s3transfer<0.2.0,>=0.1.12 in /usr/local/lib/python3.6/dist-packages (from awscli>=1.11.91->allennlp) (0.1.13)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from awscli>=1.11.91->allennlp) (0.14)\n",
            "Requirement already satisfied: PyYAML<=3.13,>=3.10 in /usr/local/lib/python3.6/dist-packages (from awscli>=1.11.91->allennlp) (3.13)\n",
            "Requirement already satisfied: rsa<=3.5.0,>=3.1.2 in /usr/local/lib/python3.6/dist-packages (from awscli>=1.11.91->allennlp) (3.4.2)\n",
            "Requirement already satisfied: greenlet>=0.4.14; platform_python_implementation == \"CPython\" in /usr/local/lib/python3.6/dist-packages (from gevent==1.3.6->allennlp) (0.4.15)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi==1.11.5->allennlp) (2.19)\n",
            "Requirement already satisfied: protobuf>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorboardX==1.2->allennlp) (3.6.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (0.9.3)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (4.3.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.2.1)\n",
            "Requirement already satisfied: pluggy>=0.7 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (0.8.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (18.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (40.6.3)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.7.0)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.1,>=2.0->allennlp) (2.0.1)\n",
            "Requirement already satisfied: thinc<6.13.0,>=6.12.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.1,>=2.0->allennlp) (6.12.1)\n",
            "Requirement already satisfied: regex==2018.01.10 in /usr/local/lib/python3.6/dist-packages (from spacy<2.1,>=2.0->allennlp) (2018.1.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.1,>=2.0->allennlp) (2.0.2)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.1,>=2.0->allennlp) (0.9.6)\n",
            "Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy<2.1,>=2.0->allennlp) (1.35)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.1,>=2.0->allennlp) (1.0.1)\n",
            "Requirement already satisfied: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.1,>=2.0->allennlp) (0.2.8.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->allennlp) (0.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10->flask==1.0.2->allennlp) (1.1.0)\n",
            "Requirement already satisfied: asn1crypto>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.0.0->moto==1.3.4->allennlp) (0.24.0)\n",
            "Requirement already satisfied: future<1.0 in /usr/local/lib/python3.6/dist-packages (from python-jose<3.0.0->moto==1.3.4->allennlp) (0.16.0)\n",
            "Requirement already satisfied: ecdsa<1.0 in /usr/local/lib/python3.6/dist-packages (from python-jose<3.0.0->moto==1.3.4->allennlp) (0.13)\n",
            "Requirement already satisfied: pycryptodome<4.0.0,>=3.3.1 in /usr/local/lib/python3.6/dist-packages (from python-jose<3.0.0->moto==1.3.4->allennlp) (3.7.2)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock->moto==1.3.4->allennlp) (5.1.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from aws-xray-sdk<0.96,>=0.93->moto==1.3.4->allennlp) (1.10.11)\n",
            "Requirement already satisfied: jsonpickle in /usr/local/lib/python3.6/dist-packages (from aws-xray-sdk<0.96,>=0.93->moto==1.3.4->allennlp) (1.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from docker>=2.5.1->moto==1.3.4->allennlp) (0.4.0)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.6/dist-packages (from docker>=2.5.1->moto==1.3.4->allennlp) (0.54.0)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.2.3->numpydoc==0.8.0->allennlp) (1.1.0)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.2.3->numpydoc==0.8.0->allennlp) (2.1.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.2.3->numpydoc==0.8.0->allennlp) (18.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.2.3->numpydoc==0.8.0->allennlp) (0.7.12)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.2.3->numpydoc==0.8.0->allennlp) (1.1.0)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.2.3->numpydoc==0.8.0->allennlp) (1.2.1)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.2.3->numpydoc==0.8.0->allennlp) (2.6.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<=3.5.0,>=3.1.2->awscli>=1.11.91->allennlp) (0.4.4)\n",
            "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy<2.1,>=2.0->allennlp) (0.9.0.1)\n",
            "Requirement already satisfied: msgpack-numpy<0.4.4 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy<2.1,>=2.0->allennlp) (0.4.3.2)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy<2.1,>=2.0->allennlp) (0.9.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ASys-J6shn08",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "outputId": "69940350-4364-483c-dca5-2b8ad1841931"
      },
      "cell_type": "code",
      "source": [
        "!pip install overrides\n",
        "!pip install tqdm\n",
        "!pip install -U spacy\n",
        "!python -m spacy download en"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: overrides in /usr/local/lib/python3.6/dist-packages (1.9)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n",
            "Requirement already up-to-date: spacy in /usr/local/lib/python3.6/dist-packages (2.0.18)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.35)\n",
            "Requirement already satisfied, skipping upgrade: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.8.2)\n",
            "Requirement already satisfied, skipping upgrade: thinc<6.13.0,>=6.12.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (6.12.1)\n",
            "Requirement already satisfied, skipping upgrade: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.15.4)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.18.4)\n",
            "Requirement already satisfied, skipping upgrade: regex==2018.01.10 in /usr/local/lib/python3.6/dist-packages (from spacy) (2018.1.10)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (4.28.1)\n",
            "Requirement already satisfied, skipping upgrade: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.9.0.1)\n",
            "Requirement already satisfied, skipping upgrade: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.10.11)\n",
            "Requirement already satisfied, skipping upgrade: six<2.0.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: msgpack<0.6.0,>=0.5.6 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.5.6)\n",
            "Requirement already satisfied, skipping upgrade: msgpack-numpy<0.4.4 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.4.3.2)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2018.11.29)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.22)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.6)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy) (0.9.0)\n",
            "Requirement already satisfied: en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "\n",
            "    You can now load the model via spacy.load('en')\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ef-ChwRLiDQP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "09e5b713-80e6-49d6-af35-44a7978c84ee"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gdndoFrriYna",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "02d86bc7-381e-4f57-af6d-5951c9827ac9"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/mhagiwara/realworldnlp.git"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'realworldnlp'...\n",
            "remote: Enumerating objects: 90, done.\u001b[K\n",
            "remote: Counting objects: 100% (90/90), done.\u001b[K\n",
            "remote: Compressing objects: 100% (61/61), done.\u001b[K\n",
            "remote: Total 90 (delta 27), reused 79 (delta 16), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (90/90), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1YBBo5eri3SN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b048e7e5-d8b9-4240-9179-bf354b10d877"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "amazon_cells_labelled.txt  imdb_labelled.txt  sample_data\n",
            "drive\t\t\t   realworldnlp       yelp_labelled.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hpNVt-8okAfw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "from allennlp.common import JsonDict\n",
        "from allennlp.data import DatasetReader, Instance\n",
        "from allennlp.models import Model\n",
        "from allennlp.predictors import Predictor\n",
        "from overrides import overrides\n",
        "\n",
        "\n",
        "# You need to name your predictor and register so that `allennlp` command can recognize it\n",
        "# Note that you need to use \"@Predictor.register\", not \"@Model.register\"!\n",
        "@Predictor.register(\"sentence_classifier_predictor\")\n",
        "class SentenceClassifierPredictor(Predictor):\n",
        "    def __init__(self, model: Model, dataset_reader: DatasetReader) -> None:\n",
        "        super().__init__(model, dataset_reader)\n",
        "\n",
        "    def predict(self, tokens: List[str]) -> JsonDict:\n",
        "        return self.predict_json({\"tokens\" : tokens})\n",
        "\n",
        "    @overrides\n",
        "    def _json_to_instance(self, json_dict: JsonDict) -> Instance:\n",
        "        tokens = json_dict[\"tokens\"]\n",
        "        return self._dataset_reader.text_to_instance(tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ukDPBtcXoP5D",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "99751f79-788a-44a0-bb5f-5a223a917e0d"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-807e1239-9d07-408e-9356-d9ca9adf7a38\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-807e1239-9d07-408e-9356-d9ca9adf7a38\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving dev.txt to dev.txt\n",
            "Saving test.txt to test.txt\n",
            "Saving train.txt to train.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JRp25YXNphIv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "4910b85f-5f39-4a10-fa0e-47fd19b1c901"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "amazon_cells_labelled.txt  imdb_labelled.txt  test.txt\n",
            "dev.txt\t\t\t   realworldnlp       train.txt\n",
            "drive\t\t\t   sample_data\t      yelp_labelled.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2JddlISuplgh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "636ea00d-8c34-4585-bb1b-1974f587bbba"
      },
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MugQZs4LhsJH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5892
        },
        "outputId": "97c5b8e0-360b-4799-dc9f-677adf6b19f6"
      },
      "cell_type": "code",
      "source": [
        "from typing import Dict\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from allennlp.data.dataset_readers.stanford_sentiment_tree_bank import \\\n",
        "    StanfordSentimentTreeBankDatasetReader\n",
        "from allennlp.data.iterators import BucketIterator\n",
        "from allennlp.data.vocabulary import Vocabulary\n",
        "from allennlp.models import Model\n",
        "from allennlp.modules.seq2vec_encoders import Seq2VecEncoder, PytorchSeq2VecWrapper\n",
        "from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n",
        "from allennlp.modules.token_embedders import Embedding\n",
        "from allennlp.nn.util import get_text_field_mask\n",
        "from allennlp.training.metrics import CategoricalAccuracy\n",
        "from allennlp.training.trainer import Trainer\n",
        "\n",
        "\n",
        "\n",
        "EMBEDDING_DIM = 128\n",
        "HIDDEN_DIM = 128\n",
        "\n",
        "# Model in AllenNLP represents a model that is trained.\n",
        "@Model.register(\"lstm_classifier3\")\n",
        "class LstmClassifier(Model):\n",
        "    def __init__(self,\n",
        "                 word_embeddings: TextFieldEmbedder,\n",
        "                 encoder: Seq2VecEncoder,\n",
        "                 vocab: Vocabulary) -> None:\n",
        "        super().__init__(vocab)\n",
        "        # We need the embeddings to convert word IDs to their vector representations\n",
        "        self.word_embeddings = word_embeddings\n",
        "\n",
        "        # Seq2VecEncoder is a neural network abstraction that takes a sequence of something\n",
        "        # (usually a sequence of embedded word vectors), processes it, and returns a single\n",
        "        # vector. Oftentimes this is an RNN-based architecture (e.g., LSTM or GRU), but\n",
        "        # AllenNLP also supports CNNs and other simple architectures (for example,\n",
        "        # just averaging over the input vectors).\n",
        "        self.encoder = encoder\n",
        "\n",
        "        # After converting a sequence of vectors to a single vector, we feed it into\n",
        "        # a fully-connected linear layer to reduce the dimension to the total number of labels.\n",
        "        self.hidden2tag = torch.nn.Linear(in_features=encoder.get_output_dim(),\n",
        "                                          out_features=vocab.get_vocab_size('labels'))\n",
        "        self.accuracy = CategoricalAccuracy()\n",
        "\n",
        "        # We use the cross entropy loss because this is a classification task.\n",
        "        # Note that PyTorch's CrossEntropyLoss combines softmax and log likelihood loss,\n",
        "        # which makes it unnecessary to add a separate softmax layer.\n",
        "        self.loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    # Instances are fed to forward after batching.\n",
        "    # Fields are passed through arguments with the same name.\n",
        "    def forward(self,\n",
        "                tokens: Dict[str, torch.Tensor],\n",
        "                label: torch.Tensor = None) -> torch.Tensor:\n",
        "        # In deep NLP, when sequences of tensors in different lengths are batched together,\n",
        "        # shorter sequences get padded with zeros to make them equal length.\n",
        "        # Masking is the process to ignore extra zeros added by padding\n",
        "        mask = get_text_field_mask(tokens)\n",
        "\n",
        "        # Forward pass\n",
        "        embeddings = self.word_embeddings(tokens)\n",
        "        encoder_out = self.encoder(embeddings, mask)\n",
        "        logits = self.hidden2tag(encoder_out)\n",
        "\n",
        "        # In AllenNLP, the output of forward() is a dictionary.\n",
        "        # Your output dictionary must contain a \"loss\" key for your model to be trained.\n",
        "        output = {\"logits\": logits}\n",
        "        if label is not None:\n",
        "            self.accuracy(logits, label)\n",
        "            output[\"loss\"] = self.loss_function(logits, label)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def get_metrics(self, reset: bool = False) -> Dict[str, float]:\n",
        "        return {\"accuracy\": self.accuracy.get_metric(reset)}\n",
        "\n",
        "\n",
        "def main():\n",
        "    reader = StanfordSentimentTreeBankDatasetReader()\n",
        "\n",
        "    train_dataset = reader.read('train.txt')\n",
        "    dev_dataset = reader.read('dev.txt')\n",
        "\n",
        "    # You can optionally specify the minimum count of tokens/labels.\n",
        "    # `min_count={'tokens':3}` here means that any tokens that appear less than three times\n",
        "    # will be ignored and not included in the vocabulary.\n",
        "    vocab = Vocabulary.from_instances(train_dataset + dev_dataset,\n",
        "                                      min_count={'tokens': 3})\n",
        "\n",
        "    token_embedding = Embedding(num_embeddings=vocab.get_vocab_size('tokens'),\n",
        "                                embedding_dim=EMBEDDING_DIM)\n",
        "\n",
        "    # BasicTextFieldEmbedder takes a dict - we need an embedding just for tokens,\n",
        "    # not for labels, which are used as-is as the \"answer\" of the sentence classification\n",
        "    word_embeddings = BasicTextFieldEmbedder({\"tokens\": token_embedding})\n",
        "\n",
        "    lstm = PytorchSeq2VecWrapper(\n",
        "        torch.nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM, batch_first=True))\n",
        "\n",
        "    model = LstmClassifier(word_embeddings, lstm, vocab)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "\n",
        "    iterator = BucketIterator(batch_size=32, sorting_keys=[(\"tokens\", \"num_tokens\")])\n",
        "\n",
        "    iterator.index_with(vocab)\n",
        "\n",
        "    trainer = Trainer(model=model,\n",
        "                      optimizer=optimizer,\n",
        "                      iterator=iterator,\n",
        "                      train_dataset=train_dataset,\n",
        "                      validation_dataset=dev_dataset,\n",
        "                      patience=10,\n",
        "                      num_epochs=20)\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    tokens = ['This', 'is', 'the', 'best', 'movie', 'ever', '!']\n",
        "    predictor = SentenceClassifierPredictor(model, dataset_reader=reader)\n",
        "    logits = predictor.predict(tokens)['logits']\n",
        "    label_id = np.argmax(logits)\n",
        "\n",
        "    print(model.vocab.get_token_from_index(label_id, 'labels'))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "0it [00:00, ?it/s]\u001b[A12/29/2018 20:40:02 - INFO - allennlp.data.dataset_readers.stanford_sentiment_tree_bank -   Reading instances from lines in file at: train.txt\n",
            "\n",
            "403it [00:00, 4027.40it/s]\u001b[A\n",
            "824it [00:00, 4076.32it/s]\u001b[A\n",
            "8544it [00:02, 3329.67it/s]\n",
            "0it [00:00, ?it/s]12/29/2018 20:40:05 - INFO - allennlp.data.dataset_readers.stanford_sentiment_tree_bank -   Reading instances from lines in file at: dev.txt\n",
            "1101it [00:00, 4515.53it/s]\n",
            "12/29/2018 20:40:05 - INFO - allennlp.data.vocabulary -   Fitting token dictionary from dataset.\n",
            "100%|██████████| 9645/9645 [00:00<00:00, 39958.14it/s]\n",
            "12/29/2018 20:40:05 - INFO - allennlp.training.trainer -   Beginning training.\n",
            "12/29/2018 20:40:05 - INFO - allennlp.training.trainer -   Epoch 0/19\n",
            "12/29/2018 20:40:05 - INFO - allennlp.training.trainer -   Peak CPU memory usage MB: 316.76\n",
            "12/29/2018 20:40:05 - ERROR - allennlp.common.util -   unable to check gpu_memory_mb(), continuing\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/allennlp/common/util.py\", line 343, in gpu_memory_mb\n",
            "    encoding='utf-8')\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 336, in check_output\n",
            "    **kwargs).stdout\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 418, in run\n",
            "    output=stdout, stderr=stderr)\n",
            "subprocess.CalledProcessError: Command '['nvidia-smi', '--query-gpu=memory.used', '--format=csv,nounits,noheader']' returned non-zero exit status 9.\n",
            "12/29/2018 20:40:05 - INFO - allennlp.training.trainer -   Training\n",
            "accuracy: 0.2664, loss: 1.5795 ||: 100%|██████████| 267/267 [00:13<00:00, 19.32it/s]\n",
            "12/29/2018 20:40:19 - INFO - allennlp.training.trainer -   Validating\n",
            "accuracy: 0.2534, loss: 1.5730 ||: 100%|██████████| 35/35 [00:00<00:00, 56.01it/s]\n",
            "12/29/2018 20:40:20 - INFO - allennlp.training.trainer -                     Training |  Validation\n",
            "12/29/2018 20:40:20 - INFO - allennlp.training.trainer -   cpu_memory_MB |   316.760  |       N/A\n",
            "12/29/2018 20:40:20 - INFO - allennlp.training.trainer -   loss          |     1.579  |     1.573\n",
            "12/29/2018 20:40:20 - INFO - allennlp.training.trainer -   accuracy      |     0.266  |     0.253\n",
            "12/29/2018 20:40:20 - INFO - allennlp.training.trainer -   Epoch duration: 00:00:14\n",
            "12/29/2018 20:40:20 - INFO - allennlp.training.trainer -   Estimated training time remaining: 0:04:33\n",
            "12/29/2018 20:40:20 - INFO - allennlp.training.trainer -   Epoch 1/19\n",
            "12/29/2018 20:40:20 - INFO - allennlp.training.trainer -   Peak CPU memory usage MB: 377.8\n",
            "12/29/2018 20:40:20 - ERROR - allennlp.common.util -   unable to check gpu_memory_mb(), continuing\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/allennlp/common/util.py\", line 343, in gpu_memory_mb\n",
            "    encoding='utf-8')\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 336, in check_output\n",
            "    **kwargs).stdout\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 418, in run\n",
            "    output=stdout, stderr=stderr)\n",
            "subprocess.CalledProcessError: Command '['nvidia-smi', '--query-gpu=memory.used', '--format=csv,nounits,noheader']' returned non-zero exit status 9.\n",
            "12/29/2018 20:40:20 - INFO - allennlp.training.trainer -   Training\n",
            "accuracy: 0.2720, loss: 1.5653 ||: 100%|██████████| 267/267 [00:13<00:00, 19.14it/s]\n",
            "12/29/2018 20:40:33 - INFO - allennlp.training.trainer -   Validating\n",
            "accuracy: 0.2534, loss: 1.5731 ||: 100%|██████████| 35/35 [00:00<00:00, 69.29it/s]\n",
            "12/29/2018 20:40:34 - INFO - allennlp.training.trainer -                     Training |  Validation\n",
            "12/29/2018 20:40:34 - INFO - allennlp.training.trainer -   cpu_memory_MB |   377.800  |       N/A\n",
            "12/29/2018 20:40:34 - INFO - allennlp.training.trainer -   loss          |     1.565  |     1.573\n",
            "12/29/2018 20:40:34 - INFO - allennlp.training.trainer -   accuracy      |     0.272  |     0.253\n",
            "12/29/2018 20:40:34 - INFO - allennlp.training.trainer -   Epoch duration: 00:00:13\n",
            "12/29/2018 20:40:34 - INFO - allennlp.training.trainer -   Estimated training time remaining: 0:04:15\n",
            "12/29/2018 20:40:34 - INFO - allennlp.training.trainer -   Epoch 2/19\n",
            "12/29/2018 20:40:34 - INFO - allennlp.training.trainer -   Peak CPU memory usage MB: 384.44\n",
            "12/29/2018 20:40:34 - ERROR - allennlp.common.util -   unable to check gpu_memory_mb(), continuing\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/allennlp/common/util.py\", line 343, in gpu_memory_mb\n",
            "    encoding='utf-8')\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 336, in check_output\n",
            "    **kwargs).stdout\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 418, in run\n",
            "    output=stdout, stderr=stderr)\n",
            "subprocess.CalledProcessError: Command '['nvidia-smi', '--query-gpu=memory.used', '--format=csv,nounits,noheader']' returned non-zero exit status 9.\n",
            "12/29/2018 20:40:34 - INFO - allennlp.training.trainer -   Training\n",
            "accuracy: 0.2752, loss: 1.5574 ||: 100%|██████████| 267/267 [00:13<00:00, 18.68it/s]\n",
            "12/29/2018 20:40:47 - INFO - allennlp.training.trainer -   Validating\n",
            "accuracy: 0.2552, loss: 1.5685 ||: 100%|██████████| 35/35 [00:00<00:00, 68.31it/s]\n",
            "12/29/2018 20:40:48 - INFO - allennlp.training.trainer -                     Training |  Validation\n",
            "12/29/2018 20:40:48 - INFO - allennlp.training.trainer -   cpu_memory_MB |   384.440  |       N/A\n",
            "12/29/2018 20:40:48 - INFO - allennlp.training.trainer -   loss          |     1.557  |     1.568\n",
            "12/29/2018 20:40:48 - INFO - allennlp.training.trainer -   accuracy      |     0.275  |     0.255\n",
            "12/29/2018 20:40:48 - INFO - allennlp.training.trainer -   Epoch duration: 00:00:13\n",
            "12/29/2018 20:40:48 - INFO - allennlp.training.trainer -   Estimated training time remaining: 0:03:59\n",
            "12/29/2018 20:40:48 - INFO - allennlp.training.trainer -   Epoch 3/19\n",
            "12/29/2018 20:40:48 - INFO - allennlp.training.trainer -   Peak CPU memory usage MB: 386.768\n",
            "12/29/2018 20:40:48 - ERROR - allennlp.common.util -   unable to check gpu_memory_mb(), continuing\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/allennlp/common/util.py\", line 343, in gpu_memory_mb\n",
            "    encoding='utf-8')\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 336, in check_output\n",
            "    **kwargs).stdout\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 418, in run\n",
            "    output=stdout, stderr=stderr)\n",
            "subprocess.CalledProcessError: Command '['nvidia-smi', '--query-gpu=memory.used', '--format=csv,nounits,noheader']' returned non-zero exit status 9.\n",
            "12/29/2018 20:40:48 - INFO - allennlp.training.trainer -   Training\n",
            "accuracy: 0.2953, loss: 1.5308 ||: 100%|██████████| 267/267 [00:13<00:00, 20.19it/s]\n",
            "12/29/2018 20:41:01 - INFO - allennlp.training.trainer -   Validating\n",
            "accuracy: 0.2743, loss: 1.5571 ||: 100%|██████████| 35/35 [00:00<00:00, 67.59it/s]\n",
            "12/29/2018 20:41:01 - INFO - allennlp.training.trainer -                     Training |  Validation\n",
            "12/29/2018 20:41:01 - INFO - allennlp.training.trainer -   cpu_memory_MB |   386.768  |       N/A\n",
            "12/29/2018 20:41:01 - INFO - allennlp.training.trainer -   loss          |     1.531  |     1.557\n",
            "12/29/2018 20:41:01 - INFO - allennlp.training.trainer -   accuracy      |     0.295  |     0.274\n",
            "12/29/2018 20:41:01 - INFO - allennlp.training.trainer -   Epoch duration: 00:00:13\n",
            "12/29/2018 20:41:01 - INFO - allennlp.training.trainer -   Estimated training time remaining: 0:03:44\n",
            "12/29/2018 20:41:01 - INFO - allennlp.training.trainer -   Epoch 4/19\n",
            "12/29/2018 20:41:01 - INFO - allennlp.training.trainer -   Peak CPU memory usage MB: 389.144\n",
            "12/29/2018 20:41:01 - ERROR - allennlp.common.util -   unable to check gpu_memory_mb(), continuing\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/allennlp/common/util.py\", line 343, in gpu_memory_mb\n",
            "    encoding='utf-8')\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 336, in check_output\n",
            "    **kwargs).stdout\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 418, in run\n",
            "    output=stdout, stderr=stderr)\n",
            "subprocess.CalledProcessError: Command '['nvidia-smi', '--query-gpu=memory.used', '--format=csv,nounits,noheader']' returned non-zero exit status 9.\n",
            "12/29/2018 20:41:01 - INFO - allennlp.training.trainer -   Training\n",
            "accuracy: 0.3319, loss: 1.4702 ||: 100%|██████████| 267/267 [00:13<00:00, 19.14it/s]\n",
            "12/29/2018 20:41:15 - INFO - allennlp.training.trainer -   Validating\n",
            "accuracy: 0.2916, loss: 1.5467 ||: 100%|██████████| 35/35 [00:00<00:00, 70.08it/s]\n",
            "12/29/2018 20:41:15 - INFO - allennlp.training.trainer -                     Training |  Validation\n",
            "12/29/2018 20:41:15 - INFO - allennlp.training.trainer -   cpu_memory_MB |   389.144  |       N/A\n",
            "12/29/2018 20:41:15 - INFO - allennlp.training.trainer -   loss          |     1.470  |     1.547\n",
            "12/29/2018 20:41:15 - INFO - allennlp.training.trainer -   accuracy      |     0.332  |     0.292\n",
            "12/29/2018 20:41:15 - INFO - allennlp.training.trainer -   Epoch duration: 00:00:13\n",
            "12/29/2018 20:41:15 - INFO - allennlp.training.trainer -   Estimated training time remaining: 0:03:29\n",
            "12/29/2018 20:41:15 - INFO - allennlp.training.trainer -   Epoch 5/19\n",
            "12/29/2018 20:41:15 - INFO - allennlp.training.trainer -   Peak CPU memory usage MB: 392.668\n",
            "12/29/2018 20:41:15 - ERROR - allennlp.common.util -   unable to check gpu_memory_mb(), continuing\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/allennlp/common/util.py\", line 343, in gpu_memory_mb\n",
            "    encoding='utf-8')\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 336, in check_output\n",
            "    **kwargs).stdout\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 418, in run\n",
            "    output=stdout, stderr=stderr)\n",
            "subprocess.CalledProcessError: Command '['nvidia-smi', '--query-gpu=memory.used', '--format=csv,nounits,noheader']' returned non-zero exit status 9.\n",
            "12/29/2018 20:41:15 - INFO - allennlp.training.trainer -   Training\n",
            "accuracy: 0.3896, loss: 1.3751 ||: 100%|██████████| 267/267 [00:13<00:00, 20.20it/s]\n",
            "12/29/2018 20:41:28 - INFO - allennlp.training.trainer -   Validating\n",
            "accuracy: 0.3315, loss: 1.5512 ||: 100%|██████████| 35/35 [00:00<00:00, 69.46it/s]\n",
            "12/29/2018 20:41:29 - INFO - allennlp.training.trainer -                     Training |  Validation\n",
            "12/29/2018 20:41:29 - INFO - allennlp.training.trainer -   cpu_memory_MB |   392.668  |       N/A\n",
            "12/29/2018 20:41:29 - INFO - allennlp.training.trainer -   loss          |     1.375  |     1.551\n",
            "12/29/2018 20:41:29 - INFO - allennlp.training.trainer -   accuracy      |     0.390  |     0.332\n",
            "12/29/2018 20:41:29 - INFO - allennlp.training.trainer -   Epoch duration: 00:00:13\n",
            "12/29/2018 20:41:29 - INFO - allennlp.training.trainer -   Estimated training time remaining: 0:03:15\n",
            "12/29/2018 20:41:29 - INFO - allennlp.training.trainer -   Epoch 6/19\n",
            "12/29/2018 20:41:29 - INFO - allennlp.training.trainer -   Peak CPU memory usage MB: 392.684\n",
            "12/29/2018 20:41:29 - ERROR - allennlp.common.util -   unable to check gpu_memory_mb(), continuing\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/allennlp/common/util.py\", line 343, in gpu_memory_mb\n",
            "    encoding='utf-8')\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 336, in check_output\n",
            "    **kwargs).stdout\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 418, in run\n",
            "    output=stdout, stderr=stderr)\n",
            "subprocess.CalledProcessError: Command '['nvidia-smi', '--query-gpu=memory.used', '--format=csv,nounits,noheader']' returned non-zero exit status 9.\n",
            "12/29/2018 20:41:29 - INFO - allennlp.training.trainer -   Training\n",
            "accuracy: 0.4395, loss: 1.2862 ||: 100%|██████████| 267/267 [00:13<00:00, 19.19it/s]\n",
            "12/29/2018 20:41:43 - INFO - allennlp.training.trainer -   Validating\n",
            "accuracy: 0.3424, loss: 1.5764 ||: 100%|██████████| 35/35 [00:00<00:00, 68.72it/s]\n",
            "12/29/2018 20:41:43 - INFO - allennlp.training.trainer -                     Training |  Validation\n",
            "12/29/2018 20:41:43 - INFO - allennlp.training.trainer -   cpu_memory_MB |   392.684  |       N/A\n",
            "12/29/2018 20:41:43 - INFO - allennlp.training.trainer -   loss          |     1.286  |     1.576\n",
            "12/29/2018 20:41:43 - INFO - allennlp.training.trainer -   accuracy      |     0.439  |     0.342\n",
            "12/29/2018 20:41:43 - INFO - allennlp.training.trainer -   Epoch duration: 00:00:14\n",
            "12/29/2018 20:41:43 - INFO - allennlp.training.trainer -   Estimated training time remaining: 0:03:02\n",
            "12/29/2018 20:41:43 - INFO - allennlp.training.trainer -   Epoch 7/19\n",
            "12/29/2018 20:41:43 - INFO - allennlp.training.trainer -   Peak CPU memory usage MB: 392.684\n",
            "12/29/2018 20:41:43 - ERROR - allennlp.common.util -   unable to check gpu_memory_mb(), continuing\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/allennlp/common/util.py\", line 343, in gpu_memory_mb\n",
            "    encoding='utf-8')\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 336, in check_output\n",
            "    **kwargs).stdout\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 418, in run\n",
            "    output=stdout, stderr=stderr)\n",
            "subprocess.CalledProcessError: Command '['nvidia-smi', '--query-gpu=memory.used', '--format=csv,nounits,noheader']' returned non-zero exit status 9.\n",
            "12/29/2018 20:41:43 - INFO - allennlp.training.trainer -   Training\n",
            "accuracy: 0.4902, loss: 1.1906 ||: 100%|██████████| 267/267 [00:13<00:00, 21.56it/s]\n",
            "12/29/2018 20:41:57 - INFO - allennlp.training.trainer -   Validating\n",
            "accuracy: 0.3470, loss: 1.5637 ||: 100%|██████████| 35/35 [00:00<00:00, 68.00it/s]\n",
            "12/29/2018 20:41:57 - INFO - allennlp.training.trainer -                     Training |  Validation\n",
            "12/29/2018 20:41:57 - INFO - allennlp.training.trainer -   cpu_memory_MB |   392.684  |       N/A\n",
            "12/29/2018 20:41:57 - INFO - allennlp.training.trainer -   loss          |     1.191  |     1.564\n",
            "12/29/2018 20:41:57 - INFO - allennlp.training.trainer -   accuracy      |     0.490  |     0.347\n",
            "12/29/2018 20:41:57 - INFO - allennlp.training.trainer -   Epoch duration: 00:00:13\n",
            "12/29/2018 20:41:57 - INFO - allennlp.training.trainer -   Estimated training time remaining: 0:02:48\n",
            "12/29/2018 20:41:57 - INFO - allennlp.training.trainer -   Epoch 8/19\n",
            "12/29/2018 20:41:57 - INFO - allennlp.training.trainer -   Peak CPU memory usage MB: 392.684\n",
            "12/29/2018 20:41:57 - ERROR - allennlp.common.util -   unable to check gpu_memory_mb(), continuing\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/allennlp/common/util.py\", line 343, in gpu_memory_mb\n",
            "    encoding='utf-8')\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 336, in check_output\n",
            "    **kwargs).stdout\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 418, in run\n",
            "    output=stdout, stderr=stderr)\n",
            "subprocess.CalledProcessError: Command '['nvidia-smi', '--query-gpu=memory.used', '--format=csv,nounits,noheader']' returned non-zero exit status 9.\n",
            "12/29/2018 20:41:57 - INFO - allennlp.training.trainer -   Training\n",
            "accuracy: 0.5538, loss: 1.0876 ||: 100%|██████████| 267/267 [00:13<00:00, 19.59it/s]\n",
            "12/29/2018 20:42:11 - INFO - allennlp.training.trainer -   Validating\n",
            "accuracy: 0.3569, loss: 1.5910 ||: 100%|██████████| 35/35 [00:00<00:00, 68.81it/s]\n",
            "12/29/2018 20:42:12 - INFO - allennlp.training.trainer -                     Training |  Validation\n",
            "12/29/2018 20:42:12 - INFO - allennlp.training.trainer -   cpu_memory_MB |   392.684  |       N/A\n",
            "12/29/2018 20:42:12 - INFO - allennlp.training.trainer -   loss          |     1.088  |     1.591\n",
            "12/29/2018 20:42:12 - INFO - allennlp.training.trainer -   accuracy      |     0.554  |     0.357\n",
            "12/29/2018 20:42:12 - INFO - allennlp.training.trainer -   Epoch duration: 00:00:14\n",
            "12/29/2018 20:42:12 - INFO - allennlp.training.trainer -   Estimated training time remaining: 0:02:34\n",
            "12/29/2018 20:42:12 - INFO - allennlp.training.trainer -   Epoch 9/19\n",
            "12/29/2018 20:42:12 - INFO - allennlp.training.trainer -   Peak CPU memory usage MB: 394.716\n",
            "12/29/2018 20:42:12 - ERROR - allennlp.common.util -   unable to check gpu_memory_mb(), continuing\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/allennlp/common/util.py\", line 343, in gpu_memory_mb\n",
            "    encoding='utf-8')\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 336, in check_output\n",
            "    **kwargs).stdout\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 418, in run\n",
            "    output=stdout, stderr=stderr)\n",
            "subprocess.CalledProcessError: Command '['nvidia-smi', '--query-gpu=memory.used', '--format=csv,nounits,noheader']' returned non-zero exit status 9.\n",
            "12/29/2018 20:42:12 - INFO - allennlp.training.trainer -   Training\n",
            "accuracy: 0.6073, loss: 0.9757 ||: 100%|██████████| 267/267 [00:13<00:00, 20.09it/s]\n",
            "12/29/2018 20:42:25 - INFO - allennlp.training.trainer -   Validating\n",
            "accuracy: 0.3642, loss: 1.7090 ||: 100%|██████████| 35/35 [00:00<00:00, 69.81it/s]\n",
            "12/29/2018 20:42:25 - INFO - allennlp.training.trainer -                     Training |  Validation\n",
            "12/29/2018 20:42:25 - INFO - allennlp.training.trainer -   cpu_memory_MB |   394.716  |       N/A\n",
            "12/29/2018 20:42:25 - INFO - allennlp.training.trainer -   loss          |     0.976  |     1.709\n",
            "12/29/2018 20:42:25 - INFO - allennlp.training.trainer -   accuracy      |     0.607  |     0.364\n",
            "12/29/2018 20:42:25 - INFO - allennlp.training.trainer -   Epoch duration: 00:00:13\n",
            "12/29/2018 20:42:25 - INFO - allennlp.training.trainer -   Estimated training time remaining: 0:02:20\n",
            "12/29/2018 20:42:25 - INFO - allennlp.training.trainer -   Epoch 10/19\n",
            "12/29/2018 20:42:25 - INFO - allennlp.training.trainer -   Peak CPU memory usage MB: 394.984\n",
            "12/29/2018 20:42:25 - ERROR - allennlp.common.util -   unable to check gpu_memory_mb(), continuing\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/allennlp/common/util.py\", line 343, in gpu_memory_mb\n",
            "    encoding='utf-8')\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 336, in check_output\n",
            "    **kwargs).stdout\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 418, in run\n",
            "    output=stdout, stderr=stderr)\n",
            "subprocess.CalledProcessError: Command '['nvidia-smi', '--query-gpu=memory.used', '--format=csv,nounits,noheader']' returned non-zero exit status 9.\n",
            "12/29/2018 20:42:25 - INFO - allennlp.training.trainer -   Training\n",
            "accuracy: 0.6431, loss: 0.8848 ||: 100%|██████████| 267/267 [00:13<00:00, 19.87it/s]\n",
            "12/29/2018 20:42:39 - INFO - allennlp.training.trainer -   Validating\n",
            "accuracy: 0.3697, loss: 1.7676 ||: 100%|██████████| 35/35 [00:00<00:00, 68.27it/s]\n",
            "12/29/2018 20:42:39 - INFO - allennlp.training.trainer -                     Training |  Validation\n",
            "12/29/2018 20:42:39 - INFO - allennlp.training.trainer -   cpu_memory_MB |   394.984  |       N/A\n",
            "12/29/2018 20:42:39 - INFO - allennlp.training.trainer -   loss          |     0.885  |     1.768\n",
            "12/29/2018 20:42:39 - INFO - allennlp.training.trainer -   accuracy      |     0.643  |     0.370\n",
            "12/29/2018 20:42:39 - INFO - allennlp.training.trainer -   Epoch duration: 00:00:14\n",
            "12/29/2018 20:42:39 - INFO - allennlp.training.trainer -   Estimated training time remaining: 0:02:06\n",
            "12/29/2018 20:42:39 - INFO - allennlp.training.trainer -   Epoch 11/19\n",
            "12/29/2018 20:42:39 - INFO - allennlp.training.trainer -   Peak CPU memory usage MB: 394.984\n",
            "12/29/2018 20:42:39 - ERROR - allennlp.common.util -   unable to check gpu_memory_mb(), continuing\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/allennlp/common/util.py\", line 343, in gpu_memory_mb\n",
            "    encoding='utf-8')\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 336, in check_output\n",
            "    **kwargs).stdout\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 418, in run\n",
            "    output=stdout, stderr=stderr)\n",
            "subprocess.CalledProcessError: Command '['nvidia-smi', '--query-gpu=memory.used', '--format=csv,nounits,noheader']' returned non-zero exit status 9.\n",
            "12/29/2018 20:42:39 - INFO - allennlp.training.trainer -   Training\n",
            "accuracy: 0.6763, loss: 0.8088 ||: 100%|██████████| 267/267 [00:13<00:00, 20.63it/s]\n",
            "12/29/2018 20:42:53 - INFO - allennlp.training.trainer -   Validating\n",
            "accuracy: 0.3633, loss: 1.8376 ||: 100%|██████████| 35/35 [00:00<00:00, 68.96it/s]\n",
            "12/29/2018 20:42:53 - INFO - allennlp.training.trainer -                     Training |  Validation\n",
            "12/29/2018 20:42:53 - INFO - allennlp.training.trainer -   cpu_memory_MB |   394.984  |       N/A\n",
            "12/29/2018 20:42:53 - INFO - allennlp.training.trainer -   loss          |     0.809  |     1.838\n",
            "12/29/2018 20:42:53 - INFO - allennlp.training.trainer -   accuracy      |     0.676  |     0.363\n",
            "12/29/2018 20:42:53 - INFO - allennlp.training.trainer -   Epoch duration: 00:00:14\n",
            "12/29/2018 20:42:53 - INFO - allennlp.training.trainer -   Estimated training time remaining: 0:01:52\n",
            "12/29/2018 20:42:53 - INFO - allennlp.training.trainer -   Epoch 12/19\n",
            "12/29/2018 20:42:53 - INFO - allennlp.training.trainer -   Peak CPU memory usage MB: 394.984\n",
            "12/29/2018 20:42:53 - ERROR - allennlp.common.util -   unable to check gpu_memory_mb(), continuing\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/allennlp/common/util.py\", line 343, in gpu_memory_mb\n",
            "    encoding='utf-8')\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 336, in check_output\n",
            "    **kwargs).stdout\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 418, in run\n",
            "    output=stdout, stderr=stderr)\n",
            "subprocess.CalledProcessError: Command '['nvidia-smi', '--query-gpu=memory.used', '--format=csv,nounits,noheader']' returned non-zero exit status 9.\n",
            "12/29/2018 20:42:53 - INFO - allennlp.training.trainer -   Training\n",
            "accuracy: 0.7072, loss: 0.7425 ||: 100%|██████████| 267/267 [00:13<00:00, 16.44it/s]\n",
            "12/29/2018 20:43:07 - INFO - allennlp.training.trainer -   Validating\n",
            "accuracy: 0.3651, loss: 1.8629 ||: 100%|██████████| 35/35 [00:00<00:00, 68.49it/s]\n",
            "12/29/2018 20:43:07 - INFO - allennlp.training.trainer -                     Training |  Validation\n",
            "12/29/2018 20:43:07 - INFO - allennlp.training.trainer -   cpu_memory_MB |   394.984  |       N/A\n",
            "12/29/2018 20:43:07 - INFO - allennlp.training.trainer -   loss          |     0.743  |     1.863\n",
            "12/29/2018 20:43:07 - INFO - allennlp.training.trainer -   accuracy      |     0.707  |     0.365\n",
            "12/29/2018 20:43:07 - INFO - allennlp.training.trainer -   Epoch duration: 00:00:13\n",
            "12/29/2018 20:43:07 - INFO - allennlp.training.trainer -   Estimated training time remaining: 0:01:38\n",
            "12/29/2018 20:43:07 - INFO - allennlp.training.trainer -   Epoch 13/19\n",
            "12/29/2018 20:43:07 - INFO - allennlp.training.trainer -   Peak CPU memory usage MB: 399.344\n",
            "12/29/2018 20:43:07 - ERROR - allennlp.common.util -   unable to check gpu_memory_mb(), continuing\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/allennlp/common/util.py\", line 343, in gpu_memory_mb\n",
            "    encoding='utf-8')\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 336, in check_output\n",
            "    **kwargs).stdout\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 418, in run\n",
            "    output=stdout, stderr=stderr)\n",
            "subprocess.CalledProcessError: Command '['nvidia-smi', '--query-gpu=memory.used', '--format=csv,nounits,noheader']' returned non-zero exit status 9.\n",
            "12/29/2018 20:43:07 - INFO - allennlp.training.trainer -   Training\n",
            "accuracy: 0.7329, loss: 0.6818 ||: 100%|██████████| 267/267 [00:13<00:00, 19.83it/s]\n",
            "12/29/2018 20:43:21 - INFO - allennlp.training.trainer -   Validating\n",
            "accuracy: 0.3651, loss: 2.0195 ||: 100%|██████████| 35/35 [00:00<00:00, 69.03it/s]\n",
            "12/29/2018 20:43:21 - INFO - allennlp.training.trainer -                     Training |  Validation\n",
            "12/29/2018 20:43:21 - INFO - allennlp.training.trainer -   cpu_memory_MB |   399.344  |       N/A\n",
            "12/29/2018 20:43:21 - INFO - allennlp.training.trainer -   loss          |     0.682  |     2.020\n",
            "12/29/2018 20:43:21 - INFO - allennlp.training.trainer -   accuracy      |     0.733  |     0.365\n",
            "12/29/2018 20:43:21 - INFO - allennlp.training.trainer -   Epoch duration: 00:00:13\n",
            "12/29/2018 20:43:21 - INFO - allennlp.training.trainer -   Estimated training time remaining: 0:01:24\n",
            "12/29/2018 20:43:21 - INFO - allennlp.training.trainer -   Epoch 14/19\n",
            "12/29/2018 20:43:21 - INFO - allennlp.training.trainer -   Peak CPU memory usage MB: 399.344\n",
            "12/29/2018 20:43:21 - ERROR - allennlp.common.util -   unable to check gpu_memory_mb(), continuing\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/allennlp/common/util.py\", line 343, in gpu_memory_mb\n",
            "    encoding='utf-8')\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 336, in check_output\n",
            "    **kwargs).stdout\n",
            "  File \"/usr/lib/python3.6/subprocess.py\", line 418, in run\n",
            "    output=stdout, stderr=stderr)\n",
            "subprocess.CalledProcessError: Command '['nvidia-smi', '--query-gpu=memory.used', '--format=csv,nounits,noheader']' returned non-zero exit status 9.\n",
            "12/29/2018 20:43:21 - INFO - allennlp.training.trainer -   Training\n",
            "accuracy: 0.7530, loss: 0.6389 ||: 100%|██████████| 267/267 [00:13<00:00, 19.88it/s]\n",
            "12/29/2018 20:43:35 - INFO - allennlp.training.trainer -   Validating\n",
            "accuracy: 0.3615, loss: 2.1173 ||: 100%|██████████| 35/35 [00:00<00:00, 68.44it/s]\n",
            "12/29/2018 20:43:35 - INFO - allennlp.training.trainer -   Ran out of patience.  Stopping training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lOj4kJn3t9bd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}